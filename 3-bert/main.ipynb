{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. 导入必要的库"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "from bertopic import BERTopic\n",
    "from transformers.pipelines import pipeline\n",
    "from umap import UMAP\n",
    "from hdbscan import HDBSCAN\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import os\n",
    "import pandas as pd\n",
    "from sklearn.metrics import silhouette_score # 移到这里，因为它在模型配置部分被使用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. 数据导入与预处理"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （1）指定文件路径\n",
    "tokenized_jsonl_path = \"\"  # 修改为实际路径\n",
    "embeddings_path = \"\"           # 修改为实际路径\n",
    "stopwords_path = \"\"               # 修改为实际路径\n",
    "\n",
    "# （2）加载分词文本及原始文本\n",
    "docs_tokens = []\n",
    "docs_text = []\n",
    "with open(tokenized_jsonl_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    for line in f:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        record = json.loads(line)\n",
    "        tokens = record.get(\"tokens\", [])\n",
    "        docs_tokens.append(\" \".join(tokens))\n",
    "        docs_text.append(record[\"text\"])\n",
    "\n",
    "print(\"文本总数:\", len(docs_tokens))\n",
    "if docs_tokens:\n",
    "    print(\"预览第一条分词结果:\", docs_tokens[0])\n",
    "    print(\"预览第一条原始文本:\", docs_text[0][:100], \"...\")\n",
    "\n",
    "# （3）加载预生成的向量\n",
    "embeddings = np.load(embeddings_path)\n",
    "print(\"加载完成的向量形状:\", embeddings.shape)\n",
    "\n",
    "# （4）加载停用词表\n",
    "with open(stopwords_path, 'r', encoding='utf-8') as f:\n",
    "    stop_words_list = f.read().splitlines()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. 模型配置与训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "# （1）词向量模型（此处为占位，可根据需求替换）\n",
    "embedding_model = pipeline(\"feature-extraction\", model=\"bert-base-chinese\")\n",
    "\n",
    "# （2）构造 CountVectorizer 向量器\n",
    "vectorizer_model = CountVectorizer(\n",
    "    stop_words=stop_words_list,\n",
    "    ngram_range=(1, 1),\n",
    "    max_df=0.999,\n",
    "    min_df=5\n",
    ")\n",
    "\n",
    "# （3）设置可修改的参数组合，探索不同 UMAP 和 HDBSCAN 参数\n",
    "umap_params_list = [\n",
    "    {\"n_neighbors\": 15, \"n_components\": 5, \"min_dist\": 0.0, \"metric\": \"cosine\", \"random_state\": 42}\n",
    "    #{\"n_neighbors\": 10, \"n_components\": 5, \"min_dist\": 0.1, \"metric\": \"cosine\", \"random_state\": 42}\n",
    "]\n",
    "hdbscan_params_list = [\n",
    "    {\"min_cluster_size\": 20, \"min_samples\": 5, \"metric\": \"euclidean\"}\n",
    "    #{\"min_cluster_size\": 15, \"min_samples\": 3, \"metric\": \"euclidean\"}\n",
    "]\n",
    "\n",
    "best_silhouette = -1\n",
    "best_topic_model = None\n",
    "best_topics = None\n",
    "best_probs = None\n",
    "best_umap_params = None\n",
    "best_hdbscan_params = None\n",
    "\n",
    "# 遍历参数组合，训练模型并计算聚类指标（silhouette score）\n",
    "for up in umap_params_list:\n",
    "    for hp in hdbscan_params_list:\n",
    "        current_umap_model = UMAP(**up)\n",
    "        current_hdbscan_model = HDBSCAN(**hp)\n",
    "        current_topic_model = BERTopic(\n",
    "            embedding_model=embedding_model,\n",
    "            vectorizer_model=vectorizer_model,\n",
    "            umap_model=current_umap_model,\n",
    "            hdbscan_model=current_hdbscan_model,\n",
    "            top_n_words=10\n",
    "        )\n",
    "        current_topics, current_probs = current_topic_model.fit_transform(docs_tokens, embeddings=embeddings)\n",
    "        # 计算轮廓系数（忽略噪声：主题编号为 -1 的文档）\n",
    "        valid_idx = [i for i, t in enumerate(current_topics) if t != -1]\n",
    "        if len(valid_idx) > 1:\n",
    "            valid_embeddings = embeddings[valid_idx]\n",
    "            valid_labels = [current_topics[i] for i in valid_idx]\n",
    "            score = silhouette_score(valid_embeddings, valid_labels, metric=\"cosine\")\n",
    "        else:\n",
    "            score = -1\n",
    "        print(f\"UMAP参数: {up}, HDBSCAN参数: {hp}, Silhouette Score: {score}\")\n",
    "        if score > best_silhouette:\n",
    "            best_silhouette = score\n",
    "            best_topic_model = current_topic_model\n",
    "            best_topics = current_topics\n",
    "            best_probs = current_probs\n",
    "            best_umap_params = up\n",
    "            best_hdbscan_params = hp\n",
    "\n",
    "print(f\"最佳参数：UMAP: {best_umap_params}, HDBSCAN: {best_hdbscan_params}, Silhouette Score: {best_silhouette}\")\n",
    "\n",
    "# （4）自动合并相似主题：调用 reduce_topics 设置为 \"auto\"\n",
    "best_topic_model.reduce_topics(docs_tokens, nr_topics=\"auto\")\n",
    "print(\"已自动合并相似主题。\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. 聚类结果输出与保存"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# （0）设置自定义后缀：在实际使用中，可手动修改 suffix 来区别不同任务或实验\n",
    "suffix = \"\"  # 根据实际需要更改\n",
    "\n",
    "# （1）输出文档级结果：主题编号、概率等，并替换回原始文本\n",
    "doc_info_df = best_topic_model.get_document_info(docs_tokens)\n",
    "doc_info_df[\"Document\"] = docs_text\n",
    "doc_info_filename = f\"topic_document_info_auto_{suffix}.csv\"\n",
    "doc_info_df.to_csv(doc_info_filename, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"自动聚类后的文档主题信息已保存至 {doc_info_filename}\")\n",
    "\n",
    "# （2）输出主题汇总表：主题编号、主题名称、主题词、代表文档及文档数量\n",
    "topic_info_df = best_topic_model.get_topic_info()\n",
    "if \"Count\" in topic_info_df.columns:\n",
    "    topic_info_df.rename(columns={\"Count\": \"Number of Documents\"}, inplace=True)\n",
    "\n",
    "rep_docs_dict = best_topic_model.get_representative_docs(docs_tokens)\n",
    "rep_docs_original = {}\n",
    "for topic, rep_docs in rep_docs_dict.items():\n",
    "    new_rep = []\n",
    "    for rep_doc in rep_docs:\n",
    "        try:\n",
    "            idx = docs_tokens.index(rep_doc)\n",
    "        except ValueError:\n",
    "            idx = None\n",
    "        if idx is not None:\n",
    "            new_rep.append(docs_text[idx])\n",
    "        else:\n",
    "            new_rep.append(rep_doc)\n",
    "    rep_docs_original[topic] = new_rep\n",
    "\n",
    "topic_info_df[\"Representative_Docs\"] = topic_info_df[\"Topic\"].apply(lambda t: rep_docs_original.get(t, []))\n",
    "if \"Top_n_words\" not in topic_info_df.columns:\n",
    "    topic_info_df[\"Top_n_words\"] = topic_info_df[\"Representation\"]\n",
    "\n",
    "topic_info_df = topic_info_df.sort_values(by=\"Topic\")\n",
    "topic_info_df = topic_info_df[[\"Topic\", \"Name\", \"Representation\", \"Representative_Docs\", \"Top_n_words\", \"Number of Documents\"]]\n",
    "\n",
    "topic_summary_filename = f\"topic_summary_auto_{suffix}.csv\"\n",
    "topic_info_df.to_csv(topic_summary_filename, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"自动聚类后的主题汇总信息已保存至 {topic_summary_filename}\")\n",
    "\n",
    "# （3）输出主题词与得分\n",
    "topics_dict = best_topic_model.get_topics()  # {topic_id: [(word, score), ...], ...}\n",
    "data_rows = []\n",
    "for t_id, word_score_list in topics_dict.items():\n",
    "    for (word, score) in word_score_list:\n",
    "        data_rows.append({\"Topic\": t_id, \"Word\": word, \"Score\": score})\n",
    "topic_word_scores_df = pd.DataFrame(data_rows)\n",
    "topic_word_filename = f\"topic_word_scores_auto_{suffix}.csv\"\n",
    "topic_word_scores_df.to_csv(topic_word_filename, index=False, encoding=\"utf-8-sig\")\n",
    "print(f\"自动聚类后的主题词得分表已保存为 {topic_word_filename}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. 结果可视化"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-1主题条形图 Topic Bar Chart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_bar = best_topic_model.visualize_barchart(top_n_topics=10)\n",
    "fig_bar_filename = f\"topic_barchart_auto_{suffix}.html\"\n",
    "fig_bar.write_html(fig_bar_filename)\n",
    "print(f\"自动聚类后的主题条形图已保存为 {fig_bar_filename}\")\n",
    "fig_bar.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-2 主题关系图 Intertopic Distance Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_topic = best_topic_model.visualize_topics()\n",
    "fig_topic_filename = f\"topic_relationship_auto_{suffix}.html\"\n",
    "fig_topic.write_html(fig_topic_filename)\n",
    "print(f\"自动聚类后的主题关系图已保存为 {fig_topic_filename}\")\n",
    "fig_topic.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-3 文档分布图 Document DataMap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reduced_embeddings = UMAP(\n",
    "    n_neighbors=10,\n",
    "    n_components=3,\n",
    "    min_dist=0.0,\n",
    "    metric=\"cosine\",\n",
    "    random_state=42\n",
    ").fit_transform(embeddings)\n",
    "fig_docs = best_topic_model.visualize_documents(\n",
    "    docs_text,\n",
    "    embeddings=reduced_embeddings,\n",
    "    hide_document_hover=True\n",
    ")\n",
    "fig_docs_filename = f\"document_distribution_auto_{suffix}.html\"\n",
    "fig_docs.write_html(fig_docs_filename)\n",
    "print(f\"自动聚类后的文档分布图已保存为 {fig_docs_filename}\")\n",
    "fig_docs.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-4 主题相似度热图 Topic Similarity Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig_heatmap = best_topic_model.visualize_heatmap()\n",
    "fig_heatmap_filename = f\"topic_heatmap_auto_{suffix}.html\"\n",
    "fig_heatmap.write_html(fig_heatmap_filename)\n",
    "print(f\"自动聚类后的主题相似度热图已保存为 {fig_heatmap_filename}\")\n",
    "fig_heatmap.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4-5 层次聚类 Hierarchical Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_distance_func = lambda X: np.maximum(0, 1 - cosine_similarity(X))\n",
    "hierarchical_topics = best_topic_model.hierarchical_topics(\n",
    "    docs_tokens,\n",
    "    distance_function=custom_distance_func\n",
    ")\n",
    "fig_hierarchy = best_topic_model.visualize_hierarchy(\n",
    "    hierarchical_topics=hierarchical_topics,\n",
    "    distance_function=custom_distance_func\n",
    ")\n",
    "fig_hierarchy_filename = f\"hierarchical_topics_auto_{suffix}.html\"\n",
    "fig_hierarchy.write_html(fig_hierarchy_filename)\n",
    "print(f\"自动聚类后的层次聚类结果已保存为 {fig_hierarchy_filename}\")\n",
    "fig_hierarchy.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
