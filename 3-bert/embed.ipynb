{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1a76899e",
   "metadata": {},
   "source": [
    "## BERT Embedding 计算\n",
    "本程序使用 BERT 计算文本的词向量，并输出为 NumPy 的 `.npy` 文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "89714cc6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/homebrew/lib/python3.10/site-packages/torch/utils/_pytree.py:185: FutureWarning: optree is installed but the version is too old to support PyTorch Dynamo in C++ pytree. C++ pytree support is disabled. Please consider upgrading optree using `python3 -m pip install --upgrade 'optree>=0.13.0'`.\n",
      "  warnings.warn(\n",
      "/opt/homebrew/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: dlopen(/opt/homebrew/lib/python3.10/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <0B637046-A38B-3A5C-80C6-E847C27DCCD5> /opt/homebrew/lib/python3.10/site-packages/torchvision/image.so\n",
      "  Expected in:     <E3D17B4A-4867-3D49-BC92-E04C28EE0F45> /opt/homebrew/lib/python3.10/site-packages/torch/lib/libtorch_cpu.dylib\n",
      "  warn(f\"Failed to load image Python extension: {e}\")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from transformers import BertTokenizer, BertModel\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f52cf81",
   "metadata": {},
   "source": [
    "### 配置参数\n",
    "设定输入文件、BERT 预训练模型、批处理大小等参数。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1e44474d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_jsonl = \"/Users/jhx/Documents/Code/weibospider/output/comment_分词.jsonl\"  # 分词后得到的JSONL\n",
    "model_name = \"bert-base-chinese\"  # 预训练模型\n",
    "output_file = \"/Users/jhx/Documents/Code/weibospider/output/comment.npy\"           # 嵌入向量保存路径\n",
    "batch_size = 16                   # 批大小"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cad22d07",
   "metadata": {},
   "source": [
    "### 读取 JSONL, 获取文本\n",
    "本示例将 tokens 拼接成空格分隔的字符串后送入 BERT，也可使用原始句子。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1dcafd2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本条数: 580\n",
      "预览第一条: 庞氏骗局 时间\n"
     ]
    }
   ],
   "source": [
    "sentences = []\n",
    "with open(tokenized_jsonl, 'r', encoding='utf-8') as fin:\n",
    "    for line in fin:\n",
    "        line = line.strip()\n",
    "        if not line:\n",
    "            continue\n",
    "        record = json.loads(line)\n",
    "        token_list = record.get(\"tokens\", [])\n",
    "        text = \" \".join(token_list)\n",
    "        sentences.append(text)\n",
    "\n",
    "print(f\"文本条数: {len(sentences)}\")\n",
    "if sentences:\n",
    "    print(f\"预览第一条: {sentences[0]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a49b8e9",
   "metadata": {},
   "source": [
    "### 加载 BERT 预训练模型和 Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6b9ba39",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(model_name)\n",
    "model = BertModel.from_pretrained(model_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6cf70014",
   "metadata": {},
   "source": [
    "### 设置计算设备\n",
    "自动检测是否有 GPU 可用。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d7beb04",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(21128, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()  # 设置为评估模式"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1a6da30",
   "metadata": {},
   "source": [
    "### 切分批次\n",
    "通过 DataLoader 处理数据，以便批量输入。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "38843232",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_loader = DataLoader(sentences, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac63b005",
   "metadata": {},
   "source": [
    "### 计算 BERT Embedding 并提取 CLS 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d93ed1d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 37/37 [00:22<00:00,  1.65it/s]\n"
     ]
    }
   ],
   "source": [
    "cls_embeddings = []\n",
    "\n",
    "for batch_sentences in tqdm(data_loader):\n",
    "    inputs = tokenizer(\n",
    "        batch_sentences,\n",
    "        padding=True,\n",
    "        truncation=True,\n",
    "        return_tensors=\"pt\",\n",
    "        max_length=512\n",
    "    )\n",
    "    inputs.to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    \n",
    "    cls_batch = outputs.last_hidden_state[:, 0].cpu().numpy()\n",
    "    cls_embeddings.append(cls_batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c264f720",
   "metadata": {},
   "source": [
    "### 拼接所有批次的 CLS 向量"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dc4726c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "最终生成的词向量 <class 'numpy.ndarray'> (580, 768)\n"
     ]
    }
   ],
   "source": [
    "cls_embeddings_np = np.vstack(cls_embeddings)\n",
    "print(\"最终生成的词向量\", type(cls_embeddings_np), cls_embeddings_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17372a0c",
   "metadata": {},
   "source": [
    "### 保存到 `.npy` 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "119c35c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "词向量存储于: /Users/jhx/Documents/Code/weibospider/output/comment.npy\n"
     ]
    }
   ],
   "source": [
    "np.save(output_file, cls_embeddings_np)\n",
    "print(f\"词向量存储于: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fc1f5c1",
   "metadata": {},
   "source": [
    "### 测试加载 `.npy` 文件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2c4a6bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "加载回来，验证一下： <class 'numpy.ndarray'> (580, 768)\n"
     ]
    }
   ],
   "source": [
    "embeddings = np.load(output_file)\n",
    "print(\"加载回来，验证一下：\", type(embeddings), embeddings.shape)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
